{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b0e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as  sns\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB, MultinomialNB\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import RocCurveDisplay, roc_curve, accuracy_score, confusion_matrix, roc_auc_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from category_encoders import OneHotEncoder, TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210721e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('/Users/lorrainelu/Desktop/DLSPH/5230/final project/Diabetes Study File 10K Dec 14 2017.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24534049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset with no date\n",
    "df = data[['Age_at_Exam', 'sBP', 'BMI', 'LDL', 'HDL', 'A1c', 'TG', 'FBS', 'Total_Cholesterol', 'Depression',\n",
    "     'HTN', 'OA', 'COPD', 'Use_of_Hypertension_Medications', 'Use_of_Corticosteroids', 'Sex', 'DIABETES']]\n",
    "\n",
    "# Define the column that will be used as the target for modeling or analysis\n",
    "target_column ='DIABETES'\n",
    "\n",
    "# List of columns that contain categorical data that has not been one-hot coded\n",
    "categorical_columns = ['Use_of_Hypertension_Medications', 'Use_of_Corticosteroids', 'Sex']\n",
    "\n",
    "# List of columns that contain numerical data (excluding categorical columns and the target column)\n",
    "numerical_columns = [c for c in df.columns if c not in categorical_columns and c != target_column]\n",
    "\n",
    "for c in categorical_columns:\n",
    "    print(df[c].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e38f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MICE imputation\n",
    "\n",
    "ros = RandomOverSampler()\n",
    "\n",
    "# Initializing the ColumnTransformer\n",
    "ct = ColumnTransformer([\n",
    "    ('one_hot_encoder', OneHotEncoder(), [c for c in categorical_columns]),\n",
    "], remainder='passthrough')  # Any other columns not specified will be passed through without any transformation\n",
    "\n",
    "# Initializing the Gradient Boosting Classifier with specified parameters\n",
    "# Used HGB because the data is sparse with lots of NANs\n",
    "# HGB supports and handles missing values coded as NANs so no imputation is needed\n",
    "random_forest = GradientBoostingClassifier(max_iter = 100, learning_rate=1.0, max_depth=1)\n",
    "\n",
    "# Creating a Pipeline:\n",
    "# First, the data goes through the specified column transformations (ct)\n",
    "# Then, the transformed data is used to train or predict using the Gradient Boosting model\n",
    "model = Pipeline([\n",
    "    ('upsampling', ros),\n",
    "    ('pre_process', ct),        # Pre-processing step: Applying column transformations\n",
    "    ('hist_boost', random_forest) # Training/prediction step: Using Gradient Boosting\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
