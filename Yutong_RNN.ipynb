{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNbFtYXjiBnJFe6A816wWIR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yutong-Lu/CHL5230FinalProject/blob/main/Yutong_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pai1SE7QtN_c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch as t\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import warnings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('Diabetes Study File 10K Dec 14 2017.xlsx')\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "ZiXuIte6tV7M",
        "outputId": "7aa94d48-ea5e-4d25-943f-c15f4d7eb7f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/openpyxl/styles/stylesheet.py:226: UserWarning: Workbook contains no default style, apply openpyxl's default\n",
            "  warn(\"Workbook contains no default style, apply openpyxl's default\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Age_at_Exam    sBP   sBP_Date        BMI   BMI_Date   LDL   LDL_Date   HDL  \\\n",
              "0           65  126.0 2013-06-11  31.000000 2013-06-11  1.66 2013-06-14  1.11   \n",
              "1           62  135.0 2014-06-19  25.846483 2014-10-17  2.49 2014-05-28  1.37   \n",
              "2           63  133.0 2012-07-31  30.900000 2011-12-01  1.65 2012-06-01   NaN   \n",
              "3           51  136.0 2014-01-06  56.710775 2014-01-06  2.80 2014-01-14  1.94   \n",
              "4           40  123.0 2015-06-12  33.067867 2015-06-12  2.48 2015-06-24  1.17   \n",
              "\n",
              "    HDL_Date  A1c  ... leastO(A1c_Date)  leastO(DM_OnsetDate)  \\\n",
              "0 2013-06-14  5.4  ...              NaN                   NaN   \n",
              "1 2014-05-28  5.8  ...              NaN                   NaN   \n",
              "2        NaT  6.1  ...              NaN                   NaN   \n",
              "3 2014-01-14  6.0  ...              NaN                   NaN   \n",
              "4 2015-06-24  5.8  ...              NaN                   NaN   \n",
              "\n",
              "  leastO(FBS_Date)  LeastOfAll A1C_BEF_DM  FBS_BEF_DM        Patient_ID  \\\n",
              "0              NaN         NaN        NaN         NaN  4001000000255903   \n",
              "1              NaN         NaN        NaN         NaN  4001000000256456   \n",
              "2              NaN         NaN        NaN         NaN  1001000000000054   \n",
              "3              NaN         NaN        NaN         NaN  4001000000259496   \n",
              "4              NaN         NaN        NaN         NaN  4001000000262094   \n",
              "\n",
              "  DM_Onset_Revised  DM_Onset_Revised_1YrPrior DIABETES  \n",
              "0              NaT                        NaT       No  \n",
              "1              NaT                        NaT       No  \n",
              "2              NaT                        NaT       No  \n",
              "3              NaT                        NaT       No  \n",
              "4              NaT                        NaT       No  \n",
              "\n",
              "[5 rows x 43 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a740f6f3-f688-499a-aca4-ec58ace7da3b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age_at_Exam</th>\n",
              "      <th>sBP</th>\n",
              "      <th>sBP_Date</th>\n",
              "      <th>BMI</th>\n",
              "      <th>BMI_Date</th>\n",
              "      <th>LDL</th>\n",
              "      <th>LDL_Date</th>\n",
              "      <th>HDL</th>\n",
              "      <th>HDL_Date</th>\n",
              "      <th>A1c</th>\n",
              "      <th>...</th>\n",
              "      <th>leastO(A1c_Date)</th>\n",
              "      <th>leastO(DM_OnsetDate)</th>\n",
              "      <th>leastO(FBS_Date)</th>\n",
              "      <th>LeastOfAll</th>\n",
              "      <th>A1C_BEF_DM</th>\n",
              "      <th>FBS_BEF_DM</th>\n",
              "      <th>Patient_ID</th>\n",
              "      <th>DM_Onset_Revised</th>\n",
              "      <th>DM_Onset_Revised_1YrPrior</th>\n",
              "      <th>DIABETES</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>65</td>\n",
              "      <td>126.0</td>\n",
              "      <td>2013-06-11</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>2013-06-11</td>\n",
              "      <td>1.66</td>\n",
              "      <td>2013-06-14</td>\n",
              "      <td>1.11</td>\n",
              "      <td>2013-06-14</td>\n",
              "      <td>5.4</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4001000000255903</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>62</td>\n",
              "      <td>135.0</td>\n",
              "      <td>2014-06-19</td>\n",
              "      <td>25.846483</td>\n",
              "      <td>2014-10-17</td>\n",
              "      <td>2.49</td>\n",
              "      <td>2014-05-28</td>\n",
              "      <td>1.37</td>\n",
              "      <td>2014-05-28</td>\n",
              "      <td>5.8</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4001000000256456</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>63</td>\n",
              "      <td>133.0</td>\n",
              "      <td>2012-07-31</td>\n",
              "      <td>30.900000</td>\n",
              "      <td>2011-12-01</td>\n",
              "      <td>1.65</td>\n",
              "      <td>2012-06-01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaT</td>\n",
              "      <td>6.1</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1001000000000054</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>51</td>\n",
              "      <td>136.0</td>\n",
              "      <td>2014-01-06</td>\n",
              "      <td>56.710775</td>\n",
              "      <td>2014-01-06</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2014-01-14</td>\n",
              "      <td>1.94</td>\n",
              "      <td>2014-01-14</td>\n",
              "      <td>6.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4001000000259496</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40</td>\n",
              "      <td>123.0</td>\n",
              "      <td>2015-06-12</td>\n",
              "      <td>33.067867</td>\n",
              "      <td>2015-06-12</td>\n",
              "      <td>2.48</td>\n",
              "      <td>2015-06-24</td>\n",
              "      <td>1.17</td>\n",
              "      <td>2015-06-24</td>\n",
              "      <td>5.8</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4001000000262094</td>\n",
              "      <td>NaT</td>\n",
              "      <td>NaT</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 43 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a740f6f3-f688-499a-aca4-ec58ace7da3b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a740f6f3-f688-499a-aca4-ec58ace7da3b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a740f6f3-f688-499a-aca4-ec58ace7da3b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a594b9ab-d10e-425e-8844-ed998d0b7e39\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a594b9ab-d10e-425e-8844-ed998d0b7e39')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a594b9ab-d10e-425e-8844-ed998d0b7e39 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The result is a series where the index is 'patient_nbr' and the value is the count of records.\n",
        "patients_with_2_or_more_records = (data.groupby('Patient_ID').apply(len) >= 2)\n",
        "\n",
        "# Filter the original dataset to include only those patients who have 2 or more records.\n",
        "patients_with_2_or_more_records_df = data[data['Patient_ID'].isin(patients_with_2_or_more_records[patients_with_2_or_more_records].index)]\n",
        "\n",
        "# Update the original 'diabetes_data' dataframe with the filtered dataframe.\n",
        "data = patients_with_2_or_more_records_df\n",
        "\n",
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fmQYZhHuUrn",
        "outputId": "33793253-7635-4a01-e78a-e0d8dc06f52c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2497, 43)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The maximum number of visits for patients\n",
        "data.groupby(['Patient_ID']).size().max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4ByDHJCyBIf",
        "outputId": "d4db7e81-a411-418c-c52f-00998af1bf4d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace categorical values with numerical equivalents\n",
        "data['DIABETES'].replace({'Yes' : 1, 'No' : 0}, inplace=True)\n",
        "data['Sex'].replace({'Female' : 1, 'Male' : 0}, inplace=True)\n",
        "\n",
        "# Create indicator for using hypertension meds/corticosteroid\n",
        "data['Use_of_Hypertension_Medications'] = data['Hypertension_Medications'].notnull().astype('int')\n",
        "data['Use_of_Corticosteroids'] = data['Corticosteroids'].notnull().astype('int')\n",
        "\n",
        "# Create a subset with no date\n",
        "df = data[['Patient_ID', 'Age_at_Exam', 'sBP', 'BMI', 'A1c', 'TG', 'FBS', 'Total_Cholesterol', 'Depression',\n",
        "     'HTN', 'OA', 'COPD', 'Use_of_Hypertension_Medications', 'Use_of_Corticosteroids', 'Sex', 'DIABETES']]\n",
        "\n",
        "numerical_columns = ['Age_at_Exam', 'sBP', 'BMI', 'A1c', 'TG', 'FBS', 'Total_Cholesterol']"
      ],
      "metadata": {
        "id": "nMS_pmqitbse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65e4a401-355b-43dd-e860-b1cd0e7ee4af"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-30218cad7ea4>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['DIABETES'].replace({'Yes' : 1, 'No' : 0}, inplace=True)\n",
            "<ipython-input-5-30218cad7ea4>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Sex'].replace({'Female' : 1, 'Male' : 0}, inplace=True)\n",
            "<ipython-input-5-30218cad7ea4>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Use_of_Hypertension_Medications'] = data['Hypertension_Medications'].notnull().astype('int')\n",
            "<ipython-input-5-30218cad7ea4>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['Use_of_Corticosteroids'] = data['Corticosteroids'].notnull().astype('int')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grouping by 'Patient_ID' and creating a list of dataframes, one per group\n",
        "grouped = df.groupby('Patient_ID')\n",
        "grouped_dfs = [group for _, group in grouped]\n",
        "\n",
        "# Splitting the groups into training and test sets with an 80:20 ratio\n",
        "train_groups, test_groups = train_test_split(grouped_dfs, test_size=0.2, random_state=42)\n",
        "\n",
        "# Reassembling the training and test datasets from the groups\n",
        "train_df = pd.concat(train_groups)\n",
        "test_df = pd.concat(test_groups)\n",
        "\n",
        "# Displaying the shape of the training and test sets\n",
        "train_df_shape = train_df.shape\n",
        "test_df_shape = test_df.shape\n",
        "\n",
        "train_df_shape, test_df_shape"
      ],
      "metadata": {
        "id": "GendIlmUtuti",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48bf4ede-3e7b-429e-d781-746c7683dea1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2017, 16), (480, 16))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing data\n",
        "scaler = StandardScaler()\n",
        "\n",
        "train_df[numerical_columns] = scaler.fit_transform(train_df[numerical_columns])\n",
        "test_df[numerical_columns] = scaler.transform(test_df[numerical_columns])"
      ],
      "metadata": {
        "id": "U3tynlQAteK3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputation\n",
        "imputer = IterativeImputer(max_iter=10, random_state=42)\n",
        "train_filled_mice = pd.DataFrame(imputer.fit_transform(train_df), columns = train_df.columns)\n",
        "test_filled_mice = pd.DataFrame(imputer.transform(test_df), columns = test_df.columns)"
      ],
      "metadata": {
        "id": "3e2Qms06thCj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Group by 'patient_nbr' and create sequences\n",
        "grouped = train_filled_mice.groupby('Patient_ID', sort=False)\n",
        "sequences = [group.drop(columns=['Patient_ID', 'DIABETES']).values for _, group in grouped]\n",
        "targets = [group['DIABETES'].iloc[-1] for _, group in grouped]  # Assuming all records for a patient have the same target\n",
        "\n",
        "# Padding sequences\n",
        "max_length = max(len(s) for s in sequences)\n",
        "# We cal also go with max_length\n",
        "padded_sequences = pad_sequences(sequences, maxlen=8, padding='post', dtype='float')\n",
        "\n",
        "padded_sequences.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1su5sTBPxEqB",
        "outputId": "8e361bb3-8522-4295-caad-2b9fa73adbec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(879, 8, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing sequences\n",
        "\n",
        "# Group by 'patient_nbr' and create sequences\n",
        "grouped_test = test_df.groupby('Patient_ID', sort=False)\n",
        "sequences_test = [group.drop(columns=['Patient_ID', 'DIABETES']).values for _, group in grouped_test]\n",
        "targets_test = [group['DIABETES'].iloc[-1] for _, group in grouped_test]  # Assuming all records for a patient have the same target\n",
        "\n",
        "# Padding sequences for the test set\n",
        "padded_sequences_test = pad_sequences(sequences_test, maxlen=8, padding='post', dtype='float')\n",
        "\n",
        "padded_sequences_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7Y03ovexy6j",
        "outputId": "35bbf864-5d19-4dc0-c5ba-2a1a7ef85b10"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(220, 8, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch as t\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = padded_sequences.shape[2]\n",
        "hidden_size = 5  # Number of hidden units in RNN\n",
        "num_classes = 1\n",
        "epochs = 1000\n",
        "learning_rate = 0.001\n",
        "batch_size = 50\n",
        "landa = 0.001  # Regularization term (lambda)\n",
        "\n",
        "# Data preparation\n",
        "train_dataset = TensorDataset(t.tensor(padded_sequences, dtype=t.float32), t.tensor(targets, dtype=t.long))\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(t.tensor(padded_sequences_test, dtype=t.float32), t.tensor(targets_test, dtype=t.long))\n",
        "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# RNN layers and additional fully connected layer\n",
        "rnn_layer1 = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
        "dropout1 = nn.Dropout(0.5)  # Add dropout between RNN layers\n",
        "# rnn_layer2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "# dropout2 = nn.Dropout(0.5)  # Add dropout between RNN layers\n",
        "fc_layer1 = nn.Linear(hidden_size, hidden_size)  # Additional fully connected layer\n",
        "fc_layer2 = nn.Linear(hidden_size, 1)  # Final output layer\n",
        "\n",
        "# Dropout layer\n",
        "dropout_fc = nn.Dropout(0.2)  # Add dropout between fully connected layers\n",
        "\n",
        "# Activation function\n",
        "tanh = nn.Tanh()\n",
        "sigmoid = nn.Sigmoid()\n",
        "\n",
        "# Loss function and optimizer\n",
        "loss_fn = nn.BCELoss()\n",
        "# optimizer = Adam(list(rnn_layer1.parameters()) + list(rnn_layer2.parameters()) + list(fc_layer1.parameters()) + list(fc_layer2.parameters()), lr=learning_rate)\n",
        "optimizer = Adam(list(rnn_layer1.parameters()) + list(fc_layer1.parameters()) + list(fc_layer2.parameters()), lr=learning_rate)\n",
        "\n",
        "# Lists to store accuracies and losses\n",
        "train_accuracy_list = []\n",
        "validation_accuracy_list = []\n",
        "train_loss_list = []\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    if epoch % 500 == 0:\n",
        "        learning_rate *= 0.9  # Learning rate scheduling\n",
        "\n",
        "    per_epoch_loss_list = []\n",
        "    for X, Y in train_data_loader:\n",
        "        # Forward pass through layers\n",
        "        out, _ = rnn_layer1(X)\n",
        "        out = dropout1(out)  # Apply dropout between RNN layers\n",
        "        # out, _ = rnn_layer2(out)\n",
        "        # out = dropout2(out)  # Apply dropout between RNN layers\n",
        "        out = out[:, -1, :]  # Get the last output of the sequence\n",
        "        out = tanh(fc_layer1(out))  # Apply activation function after first fully connected layer\n",
        "        out = dropout_fc(out)  # Apply dropout between fully connected layers\n",
        "        out = fc_layer2(out)\n",
        "        out = sigmoid(out)\n",
        "\n",
        "        # Regularization\n",
        "        # l2_term = sum([(w ** 2).sum() for w in list(rnn_layer1.parameters()) + list(rnn_layer2.parameters()) + list(fc_layer1.parameters()) + list(fc_layer2.parameters())])\n",
        "        # loss = loss_fn(out, Y) + landa * l2_term\n",
        "        loss = loss_fn(out.view(-1), Y.float())\n",
        "\n",
        "        per_epoch_loss_list.append(loss.item())\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Evaluation on training and validation data\n",
        "    rnn_layer1.eval()\n",
        "    # rnn_layer2.eval()\n",
        "    fc_layer1.eval()\n",
        "    fc_layer2.eval()\n",
        "\n",
        "    with t.no_grad():\n",
        "        # Training data\n",
        "        train_correct, train_total = 0, 0\n",
        "        for X, Y in train_data_loader:\n",
        "            out, _ = rnn_layer1(X)\n",
        "            out = dropout1(out)  # Apply dropout between RNN layers\n",
        "            # out, _ = rnn_layer2(out)\n",
        "            # out = dropout2(out)  # Apply dropout between RNN layers\n",
        "            out = out[:, -1, :]\n",
        "            out = tanh(fc_layer1(out))\n",
        "            out = dropout_fc(out)  # Apply dropout between fully connected layers\n",
        "            out = fc_layer2(out)\n",
        "            probs = sigmoid(out)\n",
        "            predicted = (probs >= 0.5).type(t.LongTensor).view(-1)\n",
        "            train_total += Y.size(0)\n",
        "            train_correct += (predicted == Y).sum().item()\n",
        "        train_accuracy = 100 * train_correct / train_total\n",
        "\n",
        "        # Validation data\n",
        "        validation_correct, validation_total = 0, 0\n",
        "        for X, Y in test_data_loader:\n",
        "            out, _ = rnn_layer1(X)\n",
        "            out = dropout1(out)  # Apply dropout between RNN layers\n",
        "            # out, _ = rnn_layer2(out)\n",
        "            # out = dropout2(out)  # Apply dropout between RNN layers\n",
        "            out = out[:, -1, :]\n",
        "            out = tanh(fc_layer1(out))\n",
        "            out = dropout_fc(out)  # Apply dropout between fully connected layers\n",
        "            out = fc_layer2(out)\n",
        "            probs = sigmoid(out)\n",
        "            predicted = (probs >= 0.5).type(t.LongTensor).view(-1)\n",
        "            validation_total += Y.size(0)\n",
        "            validation_correct += (predicted == Y).sum().item()\n",
        "        validation_accuracy = 100 * validation_correct / validation_total\n",
        "\n",
        "        # Print accuracy for the current epoch\n",
        "        print(f'Epoch {epoch}/{epochs} ---> Train Accuracy: {train_accuracy}%, Validation Accuracy: {validation_accuracy}%')\n",
        "\n",
        "        # Append accuracy values to lists\n",
        "        train_accuracy_list.append(train_accuracy)\n",
        "        validation_accuracy_list.append(validation_accuracy)\n",
        "\n",
        "    # Calculate and append the average loss for the epoch\n",
        "    train_loss_list.append(sum(per_epoch_loss_list) / len(per_epoch_loss_list))\n",
        "\n",
        "    # Set the model back to train mode\n",
        "    rnn_layer1.train()\n",
        "    # rnn_layer2.train()\n",
        "    fc_layer1.train()\n",
        "    fc_layer2.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11e0dRRczF5x",
        "outputId": "8705f959-d3f1-4707-fd5a-7062a3af9caf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/1000 ---> Train Accuracy: 30.37542662116041%, Validation Accuracy: 28.636363636363637%\n",
            "Epoch 1/1000 ---> Train Accuracy: 30.489192263936292%, Validation Accuracy: 28.636363636363637%\n",
            "Epoch 2/1000 ---> Train Accuracy: 34.243458475540386%, Validation Accuracy: 37.72727272727273%\n",
            "Epoch 3/1000 ---> Train Accuracy: 46.87144482366325%, Validation Accuracy: 38.63636363636363%\n",
            "Epoch 4/1000 ---> Train Accuracy: 56.42775881683732%, Validation Accuracy: 60.0%\n",
            "Epoch 5/1000 ---> Train Accuracy: 61.66097838452787%, Validation Accuracy: 67.72727272727273%\n",
            "Epoch 6/1000 ---> Train Accuracy: 65.30147895335608%, Validation Accuracy: 67.27272727272727%\n",
            "Epoch 7/1000 ---> Train Accuracy: 65.98407281001138%, Validation Accuracy: 66.81818181818181%\n",
            "Epoch 8/1000 ---> Train Accuracy: 68.82821387940842%, Validation Accuracy: 69.0909090909091%\n",
            "Epoch 9/1000 ---> Train Accuracy: 68.14562002275314%, Validation Accuracy: 69.54545454545455%\n",
            "Epoch 10/1000 ---> Train Accuracy: 67.80432309442548%, Validation Accuracy: 69.54545454545455%\n",
            "Epoch 11/1000 ---> Train Accuracy: 69.39704209328782%, Validation Accuracy: 68.63636363636364%\n",
            "Epoch 12/1000 ---> Train Accuracy: 71.55858930602957%, Validation Accuracy: 73.63636363636364%\n",
            "Epoch 13/1000 ---> Train Accuracy: 72.92377701934016%, Validation Accuracy: 74.54545454545455%\n",
            "Epoch 14/1000 ---> Train Accuracy: 76.45051194539249%, Validation Accuracy: 80.9090909090909%\n",
            "Epoch 15/1000 ---> Train Accuracy: 78.38452787258248%, Validation Accuracy: 75.45454545454545%\n",
            "Epoch 16/1000 ---> Train Accuracy: 81.00113765642776%, Validation Accuracy: 78.63636363636364%\n",
            "Epoch 17/1000 ---> Train Accuracy: 81.91126279863481%, Validation Accuracy: 78.18181818181819%\n",
            "Epoch 18/1000 ---> Train Accuracy: 82.0250284414107%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 19/1000 ---> Train Accuracy: 82.48009101251422%, Validation Accuracy: 80.9090909090909%\n",
            "Epoch 20/1000 ---> Train Accuracy: 83.16268486916951%, Validation Accuracy: 81.36363636363636%\n",
            "Epoch 21/1000 ---> Train Accuracy: 81.79749715585893%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 22/1000 ---> Train Accuracy: 82.70762229806598%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 23/1000 ---> Train Accuracy: 83.61774744027304%, Validation Accuracy: 81.36363636363636%\n",
            "Epoch 24/1000 ---> Train Accuracy: 82.93515358361775%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 25/1000 ---> Train Accuracy: 82.70762229806598%, Validation Accuracy: 81.81818181818181%\n",
            "Epoch 26/1000 ---> Train Accuracy: 83.16268486916951%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 27/1000 ---> Train Accuracy: 85.21046643913539%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 28/1000 ---> Train Accuracy: 84.52787258248009%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 29/1000 ---> Train Accuracy: 84.98293515358361%, Validation Accuracy: 86.81818181818181%\n",
            "Epoch 30/1000 ---> Train Accuracy: 84.52787258248009%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 31/1000 ---> Train Accuracy: 85.21046643913539%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 32/1000 ---> Train Accuracy: 85.43799772468715%, Validation Accuracy: 80.9090909090909%\n",
            "Epoch 33/1000 ---> Train Accuracy: 84.86916951080774%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 34/1000 ---> Train Accuracy: 83.8452787258248%, Validation Accuracy: 86.81818181818181%\n",
            "Epoch 35/1000 ---> Train Accuracy: 85.21046643913539%, Validation Accuracy: 80.45454545454545%\n",
            "Epoch 36/1000 ---> Train Accuracy: 84.86916951080774%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 37/1000 ---> Train Accuracy: 85.43799772468715%, Validation Accuracy: 80.45454545454545%\n",
            "Epoch 38/1000 ---> Train Accuracy: 84.86916951080774%, Validation Accuracy: 79.0909090909091%\n",
            "Epoch 39/1000 ---> Train Accuracy: 84.30034129692832%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 40/1000 ---> Train Accuracy: 85.66552901023891%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 41/1000 ---> Train Accuracy: 84.86916951080774%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 42/1000 ---> Train Accuracy: 85.32423208191126%, Validation Accuracy: 85.0%\n",
            "Epoch 43/1000 ---> Train Accuracy: 86.3481228668942%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 44/1000 ---> Train Accuracy: 86.57565415244596%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 45/1000 ---> Train Accuracy: 85.66552901023891%, Validation Accuracy: 81.81818181818181%\n",
            "Epoch 46/1000 ---> Train Accuracy: 86.57565415244596%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 47/1000 ---> Train Accuracy: 85.55176336746302%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 48/1000 ---> Train Accuracy: 86.68941979522184%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 49/1000 ---> Train Accuracy: 86.3481228668942%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 50/1000 ---> Train Accuracy: 87.82707622298066%, Validation Accuracy: 79.0909090909091%\n",
            "Epoch 51/1000 ---> Train Accuracy: 86.68941979522184%, Validation Accuracy: 80.9090909090909%\n",
            "Epoch 52/1000 ---> Train Accuracy: 86.12059158134244%, Validation Accuracy: 81.36363636363636%\n",
            "Epoch 53/1000 ---> Train Accuracy: 86.00682593856655%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 54/1000 ---> Train Accuracy: 86.46188850967008%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 55/1000 ---> Train Accuracy: 85.0967007963595%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 56/1000 ---> Train Accuracy: 86.23435722411831%, Validation Accuracy: 81.81818181818181%\n",
            "Epoch 57/1000 ---> Train Accuracy: 86.12059158134244%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 58/1000 ---> Train Accuracy: 86.9169510807736%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 59/1000 ---> Train Accuracy: 87.14448236632536%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 60/1000 ---> Train Accuracy: 86.23435722411831%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 61/1000 ---> Train Accuracy: 88.05460750853243%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 62/1000 ---> Train Accuracy: 87.03071672354949%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 63/1000 ---> Train Accuracy: 87.03071672354949%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 64/1000 ---> Train Accuracy: 86.80318543799773%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 65/1000 ---> Train Accuracy: 87.48577929465301%, Validation Accuracy: 81.81818181818181%\n",
            "Epoch 66/1000 ---> Train Accuracy: 87.25824800910125%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 67/1000 ---> Train Accuracy: 86.46188850967008%, Validation Accuracy: 80.9090909090909%\n",
            "Epoch 68/1000 ---> Train Accuracy: 88.1683731513083%, Validation Accuracy: 85.0%\n",
            "Epoch 69/1000 ---> Train Accuracy: 87.94084186575654%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 70/1000 ---> Train Accuracy: 87.37201365187714%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 71/1000 ---> Train Accuracy: 87.03071672354949%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 72/1000 ---> Train Accuracy: 87.94084186575654%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 73/1000 ---> Train Accuracy: 87.03071672354949%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 74/1000 ---> Train Accuracy: 86.12059158134244%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 75/1000 ---> Train Accuracy: 87.14448236632536%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 76/1000 ---> Train Accuracy: 87.14448236632536%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 77/1000 ---> Train Accuracy: 86.80318543799773%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 78/1000 ---> Train Accuracy: 87.71331058020478%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 79/1000 ---> Train Accuracy: 87.03071672354949%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 80/1000 ---> Train Accuracy: 87.82707622298066%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 81/1000 ---> Train Accuracy: 87.48577929465301%, Validation Accuracy: 80.9090909090909%\n",
            "Epoch 82/1000 ---> Train Accuracy: 87.82707622298066%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 83/1000 ---> Train Accuracy: 88.1683731513083%, Validation Accuracy: 81.81818181818181%\n",
            "Epoch 84/1000 ---> Train Accuracy: 86.3481228668942%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 85/1000 ---> Train Accuracy: 88.05460750853243%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 86/1000 ---> Train Accuracy: 86.57565415244596%, Validation Accuracy: 81.81818181818181%\n",
            "Epoch 87/1000 ---> Train Accuracy: 87.25824800910125%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 88/1000 ---> Train Accuracy: 87.48577929465301%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 89/1000 ---> Train Accuracy: 87.37201365187714%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 90/1000 ---> Train Accuracy: 86.80318543799773%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 91/1000 ---> Train Accuracy: 87.5995449374289%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 92/1000 ---> Train Accuracy: 87.5995449374289%, Validation Accuracy: 85.0%\n",
            "Epoch 93/1000 ---> Train Accuracy: 87.03071672354949%, Validation Accuracy: 80.9090909090909%\n",
            "Epoch 94/1000 ---> Train Accuracy: 88.39590443686006%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 95/1000 ---> Train Accuracy: 86.9169510807736%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 96/1000 ---> Train Accuracy: 87.37201365187714%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 97/1000 ---> Train Accuracy: 87.03071672354949%, Validation Accuracy: 85.0%\n",
            "Epoch 98/1000 ---> Train Accuracy: 87.94084186575654%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 99/1000 ---> Train Accuracy: 87.71331058020478%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 100/1000 ---> Train Accuracy: 87.37201365187714%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 101/1000 ---> Train Accuracy: 87.14448236632536%, Validation Accuracy: 81.36363636363636%\n",
            "Epoch 102/1000 ---> Train Accuracy: 87.5995449374289%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 103/1000 ---> Train Accuracy: 87.71331058020478%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 104/1000 ---> Train Accuracy: 87.14448236632536%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 105/1000 ---> Train Accuracy: 88.50967007963595%, Validation Accuracy: 81.81818181818181%\n",
            "Epoch 106/1000 ---> Train Accuracy: 87.37201365187714%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 107/1000 ---> Train Accuracy: 88.96473265073948%, Validation Accuracy: 81.36363636363636%\n",
            "Epoch 108/1000 ---> Train Accuracy: 86.46188850967008%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 109/1000 ---> Train Accuracy: 88.05460750853243%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 110/1000 ---> Train Accuracy: 88.39590443686006%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 111/1000 ---> Train Accuracy: 88.1683731513083%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 112/1000 ---> Train Accuracy: 88.39590443686006%, Validation Accuracy: 81.81818181818181%\n",
            "Epoch 113/1000 ---> Train Accuracy: 87.94084186575654%, Validation Accuracy: 81.81818181818181%\n",
            "Epoch 114/1000 ---> Train Accuracy: 88.39590443686006%, Validation Accuracy: 80.45454545454545%\n",
            "Epoch 115/1000 ---> Train Accuracy: 88.39590443686006%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 116/1000 ---> Train Accuracy: 87.71331058020478%, Validation Accuracy: 85.0%\n",
            "Epoch 117/1000 ---> Train Accuracy: 88.28213879408419%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 118/1000 ---> Train Accuracy: 87.82707622298066%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 119/1000 ---> Train Accuracy: 89.07849829351535%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 120/1000 ---> Train Accuracy: 88.05460750853243%, Validation Accuracy: 81.36363636363636%\n",
            "Epoch 121/1000 ---> Train Accuracy: 87.37201365187714%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 122/1000 ---> Train Accuracy: 87.5995449374289%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 123/1000 ---> Train Accuracy: 88.28213879408419%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 124/1000 ---> Train Accuracy: 88.28213879408419%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 125/1000 ---> Train Accuracy: 88.73720136518772%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 126/1000 ---> Train Accuracy: 88.62343572241183%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 127/1000 ---> Train Accuracy: 88.50967007963595%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 128/1000 ---> Train Accuracy: 89.07849829351535%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 129/1000 ---> Train Accuracy: 88.05460750853243%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 130/1000 ---> Train Accuracy: 89.30602957906711%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 131/1000 ---> Train Accuracy: 88.28213879408419%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 132/1000 ---> Train Accuracy: 88.28213879408419%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 133/1000 ---> Train Accuracy: 88.28213879408419%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 134/1000 ---> Train Accuracy: 88.05460750853243%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 135/1000 ---> Train Accuracy: 89.19226393629124%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 136/1000 ---> Train Accuracy: 88.96473265073948%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 137/1000 ---> Train Accuracy: 89.07849829351535%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 138/1000 ---> Train Accuracy: 88.62343572241183%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 139/1000 ---> Train Accuracy: 88.96473265073948%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 140/1000 ---> Train Accuracy: 88.85096700796359%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 141/1000 ---> Train Accuracy: 88.73720136518772%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 142/1000 ---> Train Accuracy: 88.73720136518772%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 143/1000 ---> Train Accuracy: 89.19226393629124%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 144/1000 ---> Train Accuracy: 88.85096700796359%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 145/1000 ---> Train Accuracy: 88.1683731513083%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 146/1000 ---> Train Accuracy: 88.73720136518772%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 147/1000 ---> Train Accuracy: 89.19226393629124%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 148/1000 ---> Train Accuracy: 88.50967007963595%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 149/1000 ---> Train Accuracy: 88.50967007963595%, Validation Accuracy: 81.81818181818181%\n",
            "Epoch 150/1000 ---> Train Accuracy: 88.05460750853243%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 151/1000 ---> Train Accuracy: 88.73720136518772%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 152/1000 ---> Train Accuracy: 89.07849829351535%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 153/1000 ---> Train Accuracy: 88.96473265073948%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 154/1000 ---> Train Accuracy: 89.76109215017065%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 155/1000 ---> Train Accuracy: 88.85096700796359%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 156/1000 ---> Train Accuracy: 89.419795221843%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 157/1000 ---> Train Accuracy: 89.419795221843%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 158/1000 ---> Train Accuracy: 89.419795221843%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 159/1000 ---> Train Accuracy: 89.19226393629124%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 160/1000 ---> Train Accuracy: 89.76109215017065%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 161/1000 ---> Train Accuracy: 88.85096700796359%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 162/1000 ---> Train Accuracy: 88.50967007963595%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 163/1000 ---> Train Accuracy: 88.28213879408419%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 164/1000 ---> Train Accuracy: 87.82707622298066%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 165/1000 ---> Train Accuracy: 88.50967007963595%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 166/1000 ---> Train Accuracy: 88.28213879408419%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 167/1000 ---> Train Accuracy: 88.50967007963595%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 168/1000 ---> Train Accuracy: 88.39590443686006%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 169/1000 ---> Train Accuracy: 89.30602957906711%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 170/1000 ---> Train Accuracy: 89.419795221843%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 171/1000 ---> Train Accuracy: 88.73720136518772%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 172/1000 ---> Train Accuracy: 88.96473265073948%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 173/1000 ---> Train Accuracy: 89.19226393629124%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 174/1000 ---> Train Accuracy: 88.50967007963595%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 175/1000 ---> Train Accuracy: 89.53356086461889%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 176/1000 ---> Train Accuracy: 88.96473265073948%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 177/1000 ---> Train Accuracy: 89.07849829351535%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 178/1000 ---> Train Accuracy: 89.76109215017065%, Validation Accuracy: 85.0%\n",
            "Epoch 179/1000 ---> Train Accuracy: 89.53356086461889%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 180/1000 ---> Train Accuracy: 89.30602957906711%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 181/1000 ---> Train Accuracy: 89.07849829351535%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 182/1000 ---> Train Accuracy: 89.53356086461889%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 183/1000 ---> Train Accuracy: 89.98862343572242%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 184/1000 ---> Train Accuracy: 89.76109215017065%, Validation Accuracy: 81.81818181818181%\n",
            "Epoch 185/1000 ---> Train Accuracy: 89.30602957906711%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 186/1000 ---> Train Accuracy: 89.64732650739477%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 187/1000 ---> Train Accuracy: 89.76109215017065%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 188/1000 ---> Train Accuracy: 88.62343572241183%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 189/1000 ---> Train Accuracy: 90.10238907849829%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 190/1000 ---> Train Accuracy: 89.76109215017065%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 191/1000 ---> Train Accuracy: 89.76109215017065%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 192/1000 ---> Train Accuracy: 89.76109215017065%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 193/1000 ---> Train Accuracy: 89.64732650739477%, Validation Accuracy: 81.81818181818181%\n",
            "Epoch 194/1000 ---> Train Accuracy: 89.30602957906711%, Validation Accuracy: 85.0%\n",
            "Epoch 195/1000 ---> Train Accuracy: 88.05460750853243%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 196/1000 ---> Train Accuracy: 89.07849829351535%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 197/1000 ---> Train Accuracy: 89.19226393629124%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 198/1000 ---> Train Accuracy: 89.419795221843%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 199/1000 ---> Train Accuracy: 89.53356086461889%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 200/1000 ---> Train Accuracy: 89.30602957906711%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 201/1000 ---> Train Accuracy: 90.44368600682594%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 202/1000 ---> Train Accuracy: 89.98862343572242%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 203/1000 ---> Train Accuracy: 89.87485779294653%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 204/1000 ---> Train Accuracy: 89.07849829351535%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 205/1000 ---> Train Accuracy: 89.98862343572242%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 206/1000 ---> Train Accuracy: 90.10238907849829%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 207/1000 ---> Train Accuracy: 90.10238907849829%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 208/1000 ---> Train Accuracy: 89.98862343572242%, Validation Accuracy: 81.81818181818181%\n",
            "Epoch 209/1000 ---> Train Accuracy: 89.53356086461889%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 210/1000 ---> Train Accuracy: 90.21615472127418%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 211/1000 ---> Train Accuracy: 89.419795221843%, Validation Accuracy: 85.0%\n",
            "Epoch 212/1000 ---> Train Accuracy: 89.30602957906711%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 213/1000 ---> Train Accuracy: 90.21615472127418%, Validation Accuracy: 85.0%\n",
            "Epoch 214/1000 ---> Train Accuracy: 90.21615472127418%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 215/1000 ---> Train Accuracy: 89.53356086461889%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 216/1000 ---> Train Accuracy: 89.64732650739477%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 217/1000 ---> Train Accuracy: 89.64732650739477%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 218/1000 ---> Train Accuracy: 89.53356086461889%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 219/1000 ---> Train Accuracy: 90.44368600682594%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 220/1000 ---> Train Accuracy: 90.32992036405005%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 221/1000 ---> Train Accuracy: 89.19226393629124%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 222/1000 ---> Train Accuracy: 88.96473265073948%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 223/1000 ---> Train Accuracy: 89.87485779294653%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 224/1000 ---> Train Accuracy: 89.87485779294653%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 225/1000 ---> Train Accuracy: 90.44368600682594%, Validation Accuracy: 85.0%\n",
            "Epoch 226/1000 ---> Train Accuracy: 89.98862343572242%, Validation Accuracy: 85.0%\n",
            "Epoch 227/1000 ---> Train Accuracy: 89.98862343572242%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 228/1000 ---> Train Accuracy: 89.53356086461889%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 229/1000 ---> Train Accuracy: 90.10238907849829%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 230/1000 ---> Train Accuracy: 89.87485779294653%, Validation Accuracy: 85.0%\n",
            "Epoch 231/1000 ---> Train Accuracy: 90.32992036405005%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 232/1000 ---> Train Accuracy: 89.64732650739477%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 233/1000 ---> Train Accuracy: 88.73720136518772%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 234/1000 ---> Train Accuracy: 89.419795221843%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 235/1000 ---> Train Accuracy: 89.53356086461889%, Validation Accuracy: 85.0%\n",
            "Epoch 236/1000 ---> Train Accuracy: 89.419795221843%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 237/1000 ---> Train Accuracy: 89.07849829351535%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 238/1000 ---> Train Accuracy: 88.96473265073948%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 239/1000 ---> Train Accuracy: 90.10238907849829%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 240/1000 ---> Train Accuracy: 90.10238907849829%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 241/1000 ---> Train Accuracy: 89.98862343572242%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 242/1000 ---> Train Accuracy: 89.98862343572242%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 243/1000 ---> Train Accuracy: 89.87485779294653%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 244/1000 ---> Train Accuracy: 89.76109215017065%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 245/1000 ---> Train Accuracy: 90.10238907849829%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 246/1000 ---> Train Accuracy: 89.76109215017065%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 247/1000 ---> Train Accuracy: 89.87485779294653%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 248/1000 ---> Train Accuracy: 89.76109215017065%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 249/1000 ---> Train Accuracy: 89.87485779294653%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 250/1000 ---> Train Accuracy: 90.10238907849829%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 251/1000 ---> Train Accuracy: 90.10238907849829%, Validation Accuracy: 85.0%\n",
            "Epoch 252/1000 ---> Train Accuracy: 90.10238907849829%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 253/1000 ---> Train Accuracy: 90.21615472127418%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 254/1000 ---> Train Accuracy: 89.53356086461889%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 255/1000 ---> Train Accuracy: 89.30602957906711%, Validation Accuracy: 85.0%\n",
            "Epoch 256/1000 ---> Train Accuracy: 90.55745164960182%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 257/1000 ---> Train Accuracy: 89.76109215017065%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 258/1000 ---> Train Accuracy: 89.87485779294653%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 259/1000 ---> Train Accuracy: 90.10238907849829%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 260/1000 ---> Train Accuracy: 90.32992036405005%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 261/1000 ---> Train Accuracy: 89.419795221843%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 262/1000 ---> Train Accuracy: 91.01251422070534%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 263/1000 ---> Train Accuracy: 89.419795221843%, Validation Accuracy: 85.0%\n",
            "Epoch 264/1000 ---> Train Accuracy: 89.64732650739477%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 265/1000 ---> Train Accuracy: 90.78498293515358%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 266/1000 ---> Train Accuracy: 90.10238907849829%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 267/1000 ---> Train Accuracy: 89.98862343572242%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 268/1000 ---> Train Accuracy: 90.32992036405005%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 269/1000 ---> Train Accuracy: 90.10238907849829%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 270/1000 ---> Train Accuracy: 89.87485779294653%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 271/1000 ---> Train Accuracy: 89.419795221843%, Validation Accuracy: 85.0%\n",
            "Epoch 272/1000 ---> Train Accuracy: 89.87485779294653%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 273/1000 ---> Train Accuracy: 89.53356086461889%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 274/1000 ---> Train Accuracy: 90.44368600682594%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 275/1000 ---> Train Accuracy: 87.94084186575654%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 276/1000 ---> Train Accuracy: 85.43799772468715%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 277/1000 ---> Train Accuracy: 85.77929465301479%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 278/1000 ---> Train Accuracy: 88.96473265073948%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 279/1000 ---> Train Accuracy: 89.64732650739477%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 280/1000 ---> Train Accuracy: 89.98862343572242%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 281/1000 ---> Train Accuracy: 89.98862343572242%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 282/1000 ---> Train Accuracy: 90.21615472127418%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 283/1000 ---> Train Accuracy: 90.10238907849829%, Validation Accuracy: 81.81818181818181%\n",
            "Epoch 284/1000 ---> Train Accuracy: 90.32992036405005%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 285/1000 ---> Train Accuracy: 90.21615472127418%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 286/1000 ---> Train Accuracy: 90.32992036405005%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 287/1000 ---> Train Accuracy: 90.21615472127418%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 288/1000 ---> Train Accuracy: 90.44368600682594%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 289/1000 ---> Train Accuracy: 89.87485779294653%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 290/1000 ---> Train Accuracy: 89.76109215017065%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 291/1000 ---> Train Accuracy: 90.10238907849829%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 292/1000 ---> Train Accuracy: 90.21615472127418%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 293/1000 ---> Train Accuracy: 88.62343572241183%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 294/1000 ---> Train Accuracy: 89.76109215017065%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 295/1000 ---> Train Accuracy: 89.419795221843%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 296/1000 ---> Train Accuracy: 89.30602957906711%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 297/1000 ---> Train Accuracy: 89.98862343572242%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 298/1000 ---> Train Accuracy: 90.89874857792947%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 299/1000 ---> Train Accuracy: 88.85096700796359%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 300/1000 ---> Train Accuracy: 87.94084186575654%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 301/1000 ---> Train Accuracy: 89.30602957906711%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 302/1000 ---> Train Accuracy: 90.21615472127418%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 303/1000 ---> Train Accuracy: 89.419795221843%, Validation Accuracy: 85.0%\n",
            "Epoch 304/1000 ---> Train Accuracy: 89.98862343572242%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 305/1000 ---> Train Accuracy: 90.55745164960182%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 306/1000 ---> Train Accuracy: 90.78498293515358%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 307/1000 ---> Train Accuracy: 90.55745164960182%, Validation Accuracy: 86.36363636363636%\n",
            "Epoch 308/1000 ---> Train Accuracy: 90.55745164960182%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 309/1000 ---> Train Accuracy: 90.32992036405005%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 310/1000 ---> Train Accuracy: 90.32992036405005%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 311/1000 ---> Train Accuracy: 91.58134243458476%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 312/1000 ---> Train Accuracy: 90.6712172923777%, Validation Accuracy: 85.0%\n",
            "Epoch 313/1000 ---> Train Accuracy: 90.89874857792947%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 314/1000 ---> Train Accuracy: 89.419795221843%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 315/1000 ---> Train Accuracy: 90.21615472127418%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 316/1000 ---> Train Accuracy: 90.89874857792947%, Validation Accuracy: 85.0%\n",
            "Epoch 317/1000 ---> Train Accuracy: 89.76109215017065%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 318/1000 ---> Train Accuracy: 89.87485779294653%, Validation Accuracy: 85.0%\n",
            "Epoch 319/1000 ---> Train Accuracy: 90.6712172923777%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 320/1000 ---> Train Accuracy: 90.21615472127418%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 321/1000 ---> Train Accuracy: 90.55745164960182%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 322/1000 ---> Train Accuracy: 90.78498293515358%, Validation Accuracy: 81.81818181818181%\n",
            "Epoch 323/1000 ---> Train Accuracy: 90.6712172923777%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 324/1000 ---> Train Accuracy: 91.01251422070534%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 325/1000 ---> Train Accuracy: 91.2400455062571%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 326/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 85.0%\n",
            "Epoch 327/1000 ---> Train Accuracy: 91.58134243458476%, Validation Accuracy: 86.36363636363636%\n",
            "Epoch 328/1000 ---> Train Accuracy: 91.01251422070534%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 329/1000 ---> Train Accuracy: 91.12627986348123%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 330/1000 ---> Train Accuracy: 90.78498293515358%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 331/1000 ---> Train Accuracy: 91.58134243458476%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 332/1000 ---> Train Accuracy: 91.12627986348123%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 333/1000 ---> Train Accuracy: 91.80887372013652%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 334/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 335/1000 ---> Train Accuracy: 91.46757679180887%, Validation Accuracy: 85.0%\n",
            "Epoch 336/1000 ---> Train Accuracy: 91.58134243458476%, Validation Accuracy: 85.0%\n",
            "Epoch 337/1000 ---> Train Accuracy: 90.21615472127418%, Validation Accuracy: 85.0%\n",
            "Epoch 338/1000 ---> Train Accuracy: 90.10238907849829%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 339/1000 ---> Train Accuracy: 90.55745164960182%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 340/1000 ---> Train Accuracy: 91.46757679180887%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 341/1000 ---> Train Accuracy: 91.35381114903299%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 342/1000 ---> Train Accuracy: 90.78498293515358%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 343/1000 ---> Train Accuracy: 91.35381114903299%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 344/1000 ---> Train Accuracy: 91.12627986348123%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 345/1000 ---> Train Accuracy: 91.46757679180887%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 346/1000 ---> Train Accuracy: 91.12627986348123%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 347/1000 ---> Train Accuracy: 91.12627986348123%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 348/1000 ---> Train Accuracy: 91.01251422070534%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 349/1000 ---> Train Accuracy: 91.2400455062571%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 350/1000 ---> Train Accuracy: 91.35381114903299%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 351/1000 ---> Train Accuracy: 90.89874857792947%, Validation Accuracy: 85.0%\n",
            "Epoch 352/1000 ---> Train Accuracy: 91.58134243458476%, Validation Accuracy: 85.0%\n",
            "Epoch 353/1000 ---> Train Accuracy: 91.35381114903299%, Validation Accuracy: 85.0%\n",
            "Epoch 354/1000 ---> Train Accuracy: 91.46757679180887%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 355/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 85.0%\n",
            "Epoch 356/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 357/1000 ---> Train Accuracy: 91.35381114903299%, Validation Accuracy: 85.0%\n",
            "Epoch 358/1000 ---> Train Accuracy: 91.9226393629124%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 359/1000 ---> Train Accuracy: 91.58134243458476%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 360/1000 ---> Train Accuracy: 91.2400455062571%, Validation Accuracy: 85.0%\n",
            "Epoch 361/1000 ---> Train Accuracy: 91.58134243458476%, Validation Accuracy: 85.0%\n",
            "Epoch 362/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 363/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 85.0%\n",
            "Epoch 364/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 365/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 366/1000 ---> Train Accuracy: 91.58134243458476%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 367/1000 ---> Train Accuracy: 91.9226393629124%, Validation Accuracy: 85.0%\n",
            "Epoch 368/1000 ---> Train Accuracy: 91.46757679180887%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 369/1000 ---> Train Accuracy: 91.9226393629124%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 370/1000 ---> Train Accuracy: 91.58134243458476%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 371/1000 ---> Train Accuracy: 90.89874857792947%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 372/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 373/1000 ---> Train Accuracy: 92.15017064846417%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 374/1000 ---> Train Accuracy: 91.9226393629124%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 375/1000 ---> Train Accuracy: 91.58134243458476%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 376/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 377/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 85.0%\n",
            "Epoch 378/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 85.0%\n",
            "Epoch 379/1000 ---> Train Accuracy: 91.80887372013652%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 380/1000 ---> Train Accuracy: 91.46757679180887%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 381/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 382/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 383/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 384/1000 ---> Train Accuracy: 91.9226393629124%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 385/1000 ---> Train Accuracy: 90.89874857792947%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 386/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 387/1000 ---> Train Accuracy: 90.6712172923777%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 388/1000 ---> Train Accuracy: 91.46757679180887%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 389/1000 ---> Train Accuracy: 91.58134243458476%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 390/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 391/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 392/1000 ---> Train Accuracy: 90.89874857792947%, Validation Accuracy: 85.0%\n",
            "Epoch 393/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 394/1000 ---> Train Accuracy: 91.2400455062571%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 395/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 396/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 85.0%\n",
            "Epoch 397/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 398/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 399/1000 ---> Train Accuracy: 91.9226393629124%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 400/1000 ---> Train Accuracy: 92.15017064846417%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 401/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 85.0%\n",
            "Epoch 402/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 403/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 85.0%\n",
            "Epoch 404/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 405/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 406/1000 ---> Train Accuracy: 91.80887372013652%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 407/1000 ---> Train Accuracy: 91.9226393629124%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 408/1000 ---> Train Accuracy: 91.35381114903299%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 409/1000 ---> Train Accuracy: 90.89874857792947%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 410/1000 ---> Train Accuracy: 91.35381114903299%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 411/1000 ---> Train Accuracy: 90.78498293515358%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 412/1000 ---> Train Accuracy: 91.9226393629124%, Validation Accuracy: 85.0%\n",
            "Epoch 413/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 414/1000 ---> Train Accuracy: 90.78498293515358%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 415/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 416/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 417/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 418/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 419/1000 ---> Train Accuracy: 91.9226393629124%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 420/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 421/1000 ---> Train Accuracy: 91.9226393629124%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 422/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 423/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 424/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 85.0%\n",
            "Epoch 425/1000 ---> Train Accuracy: 91.80887372013652%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 426/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 427/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 428/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 429/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 430/1000 ---> Train Accuracy: 91.9226393629124%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 431/1000 ---> Train Accuracy: 92.15017064846417%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 432/1000 ---> Train Accuracy: 91.01251422070534%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 433/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 85.0%\n",
            "Epoch 434/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 435/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 436/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 85.0%\n",
            "Epoch 437/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 438/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 439/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 440/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 441/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 85.0%\n",
            "Epoch 442/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 443/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 85.0%\n",
            "Epoch 444/1000 ---> Train Accuracy: 92.15017064846417%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 445/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 446/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 447/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 448/1000 ---> Train Accuracy: 92.15017064846417%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 449/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 450/1000 ---> Train Accuracy: 93.7428896473265%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 451/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 452/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 85.0%\n",
            "Epoch 453/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 454/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 455/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 456/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 457/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 458/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 459/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 460/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 461/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 462/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 85.0%\n",
            "Epoch 463/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 86.36363636363636%\n",
            "Epoch 464/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 465/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 466/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 467/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 468/1000 ---> Train Accuracy: 92.15017064846417%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 469/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 470/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 471/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 472/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 473/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 474/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 85.0%\n",
            "Epoch 475/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 476/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 477/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 478/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 479/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 480/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 481/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 482/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 483/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 85.0%\n",
            "Epoch 484/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 85.0%\n",
            "Epoch 485/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 486/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 85.0%\n",
            "Epoch 487/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 488/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 489/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 85.0%\n",
            "Epoch 490/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 491/1000 ---> Train Accuracy: 91.9226393629124%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 492/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 493/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 494/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 495/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 496/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 497/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 498/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 499/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 500/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 85.0%\n",
            "Epoch 501/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 502/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 503/1000 ---> Train Accuracy: 91.12627986348123%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 504/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 505/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 506/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 507/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 508/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 85.0%\n",
            "Epoch 509/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 85.0%\n",
            "Epoch 510/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 511/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 512/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 85.0%\n",
            "Epoch 513/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 514/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 515/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 516/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 517/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 518/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 519/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 85.0%\n",
            "Epoch 520/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 521/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 85.0%\n",
            "Epoch 522/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 523/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 85.0%\n",
            "Epoch 524/1000 ---> Train Accuracy: 93.7428896473265%, Validation Accuracy: 85.0%\n",
            "Epoch 525/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 526/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 527/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 85.0%\n",
            "Epoch 528/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 529/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 530/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 531/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 532/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 533/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 85.0%\n",
            "Epoch 534/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 535/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 536/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 537/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 538/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 539/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 540/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 541/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 542/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 543/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 544/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 545/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 85.0%\n",
            "Epoch 546/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 547/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 548/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 85.0%\n",
            "Epoch 549/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 550/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 85.0%\n",
            "Epoch 551/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 552/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 553/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 85.0%\n",
            "Epoch 554/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 555/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 556/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 557/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 558/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 559/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 560/1000 ---> Train Accuracy: 90.6712172923777%, Validation Accuracy: 85.0%\n",
            "Epoch 561/1000 ---> Train Accuracy: 91.80887372013652%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 562/1000 ---> Train Accuracy: 91.46757679180887%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 563/1000 ---> Train Accuracy: 90.21615472127418%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 564/1000 ---> Train Accuracy: 88.50967007963595%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 565/1000 ---> Train Accuracy: 87.94084186575654%, Validation Accuracy: 81.81818181818181%\n",
            "Epoch 566/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 567/1000 ---> Train Accuracy: 91.35381114903299%, Validation Accuracy: 85.0%\n",
            "Epoch 568/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 569/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 570/1000 ---> Train Accuracy: 91.9226393629124%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 571/1000 ---> Train Accuracy: 92.15017064846417%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 572/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 573/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 574/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 575/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 576/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 577/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 578/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 579/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 580/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 581/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 582/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 583/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 584/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 585/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 586/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 587/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 588/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 589/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 590/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 591/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 592/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 593/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 594/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 595/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 596/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 597/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 598/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 599/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 600/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 601/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 602/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 603/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 604/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 605/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 606/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 607/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 608/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 609/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 610/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 611/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 612/1000 ---> Train Accuracy: 93.62912400455063%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 613/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 85.0%\n",
            "Epoch 614/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 615/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 616/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 617/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 81.81818181818181%\n",
            "Epoch 618/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 619/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 620/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 621/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 622/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 623/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 624/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 625/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 626/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 627/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 628/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 629/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 630/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 631/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 632/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 633/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 634/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 635/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 636/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 637/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 638/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 639/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 640/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 641/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 642/1000 ---> Train Accuracy: 93.62912400455063%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 643/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 644/1000 ---> Train Accuracy: 93.7428896473265%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 645/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 646/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 647/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 648/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 649/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 85.0%\n",
            "Epoch 650/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 651/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 652/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 653/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 654/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 655/1000 ---> Train Accuracy: 93.8566552901024%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 656/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 657/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 658/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 85.0%\n",
            "Epoch 659/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 660/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 661/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 662/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 85.0%\n",
            "Epoch 663/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 664/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 665/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 666/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 667/1000 ---> Train Accuracy: 91.80887372013652%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 668/1000 ---> Train Accuracy: 90.6712172923777%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 669/1000 ---> Train Accuracy: 89.419795221843%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 670/1000 ---> Train Accuracy: 90.6712172923777%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 671/1000 ---> Train Accuracy: 91.2400455062571%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 672/1000 ---> Train Accuracy: 91.01251422070534%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 673/1000 ---> Train Accuracy: 91.2400455062571%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 674/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 675/1000 ---> Train Accuracy: 91.80887372013652%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 676/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 677/1000 ---> Train Accuracy: 92.15017064846417%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 678/1000 ---> Train Accuracy: 89.53356086461889%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 679/1000 ---> Train Accuracy: 90.6712172923777%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 680/1000 ---> Train Accuracy: 91.2400455062571%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 681/1000 ---> Train Accuracy: 91.2400455062571%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 682/1000 ---> Train Accuracy: 91.9226393629124%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 683/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 684/1000 ---> Train Accuracy: 91.2400455062571%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 685/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 686/1000 ---> Train Accuracy: 92.15017064846417%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 687/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 688/1000 ---> Train Accuracy: 90.6712172923777%, Validation Accuracy: 85.0%\n",
            "Epoch 689/1000 ---> Train Accuracy: 91.80887372013652%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 690/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 691/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 85.0%\n",
            "Epoch 692/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 693/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 694/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 85.0%\n",
            "Epoch 695/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 696/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 697/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 698/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 699/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 85.0%\n",
            "Epoch 700/1000 ---> Train Accuracy: 93.62912400455063%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 701/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 702/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 85.0%\n",
            "Epoch 703/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 704/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 705/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 706/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 707/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 81.81818181818181%\n",
            "Epoch 708/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 709/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 710/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 711/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 712/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 713/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 714/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 715/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 716/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 717/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 718/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 719/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 720/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 721/1000 ---> Train Accuracy: 93.62912400455063%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 722/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 723/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 85.0%\n",
            "Epoch 724/1000 ---> Train Accuracy: 93.62912400455063%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 725/1000 ---> Train Accuracy: 93.7428896473265%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 726/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 727/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 728/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 729/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 730/1000 ---> Train Accuracy: 91.9226393629124%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 731/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 732/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 733/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 734/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 85.0%\n",
            "Epoch 735/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 736/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 737/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 738/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 739/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 740/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 741/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 742/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 743/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 744/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 745/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 746/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 85.0%\n",
            "Epoch 747/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 748/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 749/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 85.0%\n",
            "Epoch 750/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 751/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 752/1000 ---> Train Accuracy: 93.7428896473265%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 753/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 754/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 755/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 756/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 757/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 758/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 759/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 760/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 761/1000 ---> Train Accuracy: 93.8566552901024%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 762/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 763/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 764/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 765/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 766/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 85.0%\n",
            "Epoch 767/1000 ---> Train Accuracy: 93.8566552901024%, Validation Accuracy: 85.0%\n",
            "Epoch 768/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 769/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 770/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 771/1000 ---> Train Accuracy: 94.08418657565416%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 772/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 773/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 85.0%\n",
            "Epoch 774/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 775/1000 ---> Train Accuracy: 93.7428896473265%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 776/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 777/1000 ---> Train Accuracy: 93.7428896473265%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 778/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 779/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 780/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 781/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 782/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 783/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 784/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 785/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 786/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 81.81818181818181%\n",
            "Epoch 787/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 788/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 789/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 790/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 791/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 792/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 793/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 794/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 795/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 796/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 797/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 798/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 799/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 800/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 801/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 802/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 803/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 804/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 85.0%\n",
            "Epoch 805/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 85.0%\n",
            "Epoch 806/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 807/1000 ---> Train Accuracy: 85.0967007963595%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 808/1000 ---> Train Accuracy: 90.55745164960182%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 809/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 810/1000 ---> Train Accuracy: 88.05460750853243%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 811/1000 ---> Train Accuracy: 89.30602957906711%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 812/1000 ---> Train Accuracy: 90.55745164960182%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 813/1000 ---> Train Accuracy: 91.01251422070534%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 814/1000 ---> Train Accuracy: 91.12627986348123%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 815/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 85.0%\n",
            "Epoch 816/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 817/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 818/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 819/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 820/1000 ---> Train Accuracy: 91.46757679180887%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 821/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 85.0%\n",
            "Epoch 822/1000 ---> Train Accuracy: 90.21615472127418%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 823/1000 ---> Train Accuracy: 89.98862343572242%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 824/1000 ---> Train Accuracy: 90.6712172923777%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 825/1000 ---> Train Accuracy: 91.80887372013652%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 826/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 827/1000 ---> Train Accuracy: 91.2400455062571%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 828/1000 ---> Train Accuracy: 91.9226393629124%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 829/1000 ---> Train Accuracy: 91.9226393629124%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 830/1000 ---> Train Accuracy: 92.15017064846417%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 831/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 85.0%\n",
            "Epoch 832/1000 ---> Train Accuracy: 92.15017064846417%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 833/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 834/1000 ---> Train Accuracy: 91.9226393629124%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 835/1000 ---> Train Accuracy: 92.15017064846417%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 836/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 837/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 85.0%\n",
            "Epoch 838/1000 ---> Train Accuracy: 90.89874857792947%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 839/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 840/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 841/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 842/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 843/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 844/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 845/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 846/1000 ---> Train Accuracy: 92.15017064846417%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 847/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 848/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 849/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 850/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 851/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 852/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 853/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 85.0%\n",
            "Epoch 854/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 855/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 856/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 857/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 858/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 859/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 860/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 861/1000 ---> Train Accuracy: 91.9226393629124%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 862/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 863/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 864/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 865/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 866/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 867/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 868/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 85.0%\n",
            "Epoch 869/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 85.0%\n",
            "Epoch 870/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 871/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 872/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 85.0%\n",
            "Epoch 873/1000 ---> Train Accuracy: 91.2400455062571%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 874/1000 ---> Train Accuracy: 91.12627986348123%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 875/1000 ---> Train Accuracy: 90.89874857792947%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 876/1000 ---> Train Accuracy: 91.12627986348123%, Validation Accuracy: 85.0%\n",
            "Epoch 877/1000 ---> Train Accuracy: 91.46757679180887%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 878/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 81.36363636363636%\n",
            "Epoch 879/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 880/1000 ---> Train Accuracy: 91.69510807736064%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 881/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 882/1000 ---> Train Accuracy: 91.35381114903299%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 883/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 884/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 885/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 82.72727272727273%\n",
            "Epoch 886/1000 ---> Train Accuracy: 91.35381114903299%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 887/1000 ---> Train Accuracy: 92.26393629124004%, Validation Accuracy: 85.0%\n",
            "Epoch 888/1000 ---> Train Accuracy: 90.44368600682594%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 889/1000 ---> Train Accuracy: 92.03640500568828%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 890/1000 ---> Train Accuracy: 91.46757679180887%, Validation Accuracy: 85.0%\n",
            "Epoch 891/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 892/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 85.0%\n",
            "Epoch 893/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 894/1000 ---> Train Accuracy: 91.2400455062571%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 895/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 896/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 897/1000 ---> Train Accuracy: 92.37770193401593%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 898/1000 ---> Train Accuracy: 92.4914675767918%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 899/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 900/1000 ---> Train Accuracy: 91.9226393629124%, Validation Accuracy: 82.27272727272727%\n",
            "Epoch 901/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 902/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 903/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 904/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 905/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 85.0%\n",
            "Epoch 906/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 85.0%\n",
            "Epoch 907/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 908/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 85.0%\n",
            "Epoch 909/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 910/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 911/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 912/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 913/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 914/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 915/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 916/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 917/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 918/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 919/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 85.0%\n",
            "Epoch 920/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 85.0%\n",
            "Epoch 921/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 922/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 923/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 924/1000 ---> Train Accuracy: 93.62912400455063%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 925/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 926/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 927/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 83.18181818181819%\n",
            "Epoch 928/1000 ---> Train Accuracy: 93.7428896473265%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 929/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 930/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 931/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 85.0%\n",
            "Epoch 932/1000 ---> Train Accuracy: 93.62912400455063%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 933/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 85.0%\n",
            "Epoch 934/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 935/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 936/1000 ---> Train Accuracy: 93.62912400455063%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 937/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 938/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 939/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 940/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 941/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 942/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 943/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 944/1000 ---> Train Accuracy: 93.62912400455063%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 945/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 946/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 947/1000 ---> Train Accuracy: 93.62912400455063%, Validation Accuracy: 85.0%\n",
            "Epoch 948/1000 ---> Train Accuracy: 93.7428896473265%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 949/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 950/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 86.36363636363636%\n",
            "Epoch 951/1000 ---> Train Accuracy: 93.62912400455063%, Validation Accuracy: 85.0%\n",
            "Epoch 952/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 953/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 954/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 955/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 956/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 957/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 958/1000 ---> Train Accuracy: 93.8566552901024%, Validation Accuracy: 85.0%\n",
            "Epoch 959/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 85.0%\n",
            "Epoch 960/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 961/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 962/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 963/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 964/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 965/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 85.0%\n",
            "Epoch 966/1000 ---> Train Accuracy: 93.7428896473265%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 967/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 968/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 969/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 970/1000 ---> Train Accuracy: 94.08418657565416%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 971/1000 ---> Train Accuracy: 93.8566552901024%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 972/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 973/1000 ---> Train Accuracy: 92.6052332195677%, Validation Accuracy: 85.9090909090909%\n",
            "Epoch 974/1000 ---> Train Accuracy: 93.7428896473265%, Validation Accuracy: 85.0%\n",
            "Epoch 975/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 976/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 977/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 86.36363636363636%\n",
            "Epoch 978/1000 ---> Train Accuracy: 92.71899886234357%, Validation Accuracy: 85.0%\n",
            "Epoch 979/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 980/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 85.0%\n",
            "Epoch 981/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 982/1000 ---> Train Accuracy: 93.51535836177474%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 983/1000 ---> Train Accuracy: 93.62912400455063%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 984/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 85.45454545454545%\n",
            "Epoch 985/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 85.0%\n",
            "Epoch 986/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 987/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 988/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 989/1000 ---> Train Accuracy: 93.62912400455063%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 990/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 991/1000 ---> Train Accuracy: 93.1740614334471%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 992/1000 ---> Train Accuracy: 93.62912400455063%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 993/1000 ---> Train Accuracy: 92.94653014789533%, Validation Accuracy: 83.63636363636364%\n",
            "Epoch 994/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 84.54545454545455%\n",
            "Epoch 995/1000 ---> Train Accuracy: 93.28782707622298%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 996/1000 ---> Train Accuracy: 93.06029579067122%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 997/1000 ---> Train Accuracy: 93.40159271899886%, Validation Accuracy: 84.0909090909091%\n",
            "Epoch 998/1000 ---> Train Accuracy: 93.62912400455063%, Validation Accuracy: 85.0%\n",
            "Epoch 999/1000 ---> Train Accuracy: 92.83276450511946%, Validation Accuracy: 84.54545454545455%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation accuracy over epochs\n",
        "plt.plot([i for i in range(len(train_accuracy_list))], train_accuracy_list, label=\"Train\")\n",
        "plt.plot([i for i in range(len(validation_accuracy_list))], validation_accuracy_list, label=\"Validation\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "4s9Vw6Zl0BY7",
        "outputId": "494d5b7b-685b-45a1-9f16-a03a19a364ac"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}